{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核心概念讲解\n",
    "\n",
    "### 1. **ChatPromptTemplate基础结构**\n",
    "```python\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "```\n",
    "- `system`: 设定AI助手的角色和行为规范\n",
    "- `human`: 用户的输入消息\n",
    "- 支持变量插值，使用`{variable_name}`语法\n",
    "\n",
    "### 2. **LCEL管道操作符 `|`**\n",
    "```python\n",
    "chain = chat_prompt | model | output_parser\n",
    "```\n",
    "这是LCEL的核心特性：\n",
    "- `|` 操作符将多个组件链接成流水线\n",
    "- 数据从左到右流动\n",
    "- 每个组件的输出成为下一个组件的输入\n",
    "\n",
    "### 3. **关键组件说明**\n",
    "\n",
    "**ChatPromptTemplate**: \n",
    "- 构建结构化的对话提示\n",
    "- 支持多种消息类型（system, human, assistant）\n",
    "- 可以包含变量占位符\n",
    "\n",
    "**Model (ChatOpenAI)**:\n",
    "- 实际的语言模型\n",
    "- 接收格式化的提示，返回AI响应\n",
    "\n",
    "**StrOutputParser**:\n",
    "- 将模型输出解析为字符串\n",
    "- 简化输出格式\n",
    "\n",
    "### 4. **高级特性**\n",
    "\n",
    "**RunnablePassthrough**:\n",
    "```python\n",
    "RunnablePassthrough.assign(processed_data=process_user_data)\n",
    "```\n",
    "- 允许在链中插入数据处理步骤\n",
    "- `assign`方法可以添加新的数据字段\n",
    "\n",
    "**占位符 (placeholder)**:\n",
    "```python\n",
    "(\"placeholder\", \"{chat_history}\")\n",
    "```\n",
    "- 用于插入动态内容，如历史对话\n",
    "- 支持复杂的对话上下文管理\n",
    "\n",
    "### 5. **LCEL的优势**\n",
    "\n",
    "1. **可读性**: 管道操作符让数据流向清晰可见\n",
    "2. **模块化**: 每个组件职责单一，易于测试和维护\n",
    "3. **可组合性**: 可以轻松重组和扩展链\n",
    "4. **错误处理**: 支持内置的错误处理和回退机制\n",
    "5. **批处理**: 自动支持批量处理请求\n",
    "\n",
    "### 6. **实际使用建议**\n",
    "\n",
    "1. **模板设计**: 系统消息要明确角色定位和回答要求\n",
    "2. **变量命名**: 使用有意义的变量名提高可读性\n",
    "3. **错误处理**: 在生产环境中添加异常捕获\n",
    "4. **性能优化**: 对于频繁调用的链考虑缓存机制\n",
    "\n",
    "这种LCEL风格的写法让LangChain应用的构建变得更加直观和强大，特别适合构建复杂的AI应用流水线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain ChatPromptTemplate LCEL风格示例\n",
      "==================================================\n",
      "=== 基础示例结果 ===\n",
      "梯度下降算法是一种常用的优化算法，用于在机器学习中寻找最优模型参数。其基本思想是通过迭代的方式不断调整模型参数，使目标函数（损失函数）的值达到最小化。\n",
      "\n",
      "具体而言，梯度下降算法通过计算目标函数对于参数的梯度（导数），然后沿着梯度的反方向更新参数，以实现不断降低目标函数值的目的。这样的迭代过程会持续进行直到达到某个终止条件，比如达到最大迭代次数、参数变化很小时等。\n",
      "\n",
      "梯度下降算法主要分为批量梯度下降（Batch Gradient Descent）、随机梯度下降（Stochastic Gradient Descent）和小批量梯度下降（Mini-batch Gradient Descent）三种形式。其中，批量梯度下降会在每次迭代中使用所有样本来更新参数，随机梯度下降则是每次只使用一个样本，而小批量梯度下降则是在中间值进行权衡，同时使用一批样本。\n",
      "\n",
      "梯度下降算法的优点包括易于实现、收敛速度快等，但也存在一些缺点，比如可能陷入局部最优解、对初始值敏感等。因此，在实际应用中，需要根据具体问题和数据集的特点选择合适的梯度下降算法及调参策略。\n",
      "\n",
      "=== 对话示例结果 ===\n",
      "学习Python是一个很好的选择！你可以从以下几个步骤开始：\n",
      "\n",
      "1. 安装Python：首先，你需要安装Python解释器。你可以在Python官方网站上下载最新版本的Python并安装到你的电脑上。\n",
      "\n",
      "2. 学习基础语法：学习Python的基础语法，了解变量、数据类型、条件语句、循环语句等基本概念。\n",
      "\n",
      "3. 练习编写代码：通过练习编写简单的Python程序来巩固所学知识，比如编写一个简单的计算器程序或者输出特定格式的字符串。\n",
      "\n",
      "4. 学习函数和模块：学习如何定义和调用函数，以及如何使用模块扩展Python的功能。\n",
      "\n",
      "5. 深入学习：学习面向对象编程、异常处理、文件操作等进阶内容，掌握更多Python编程技巧。\n",
      "\n",
      "如果有任何问题或者需要帮助，随时都可以问我哦！我会尽力帮助你学习Python编程。\n",
      "\n",
      "=== 个性化示例结果 ===\n",
      "对于中级开发者来说，选择合适的神经网络架构是非常重要的。在机器学习、深度学习和自然语言处理领域，有许多常用的神经网络架构可供选择，如卷积神经网络（CNN）、循环神经网络（RNN）、长短时记忆网络（LSTM）、门控循环单元网络（GRU）等。\n",
      "\n",
      "在选择神经网络架构时，首先要考虑你的任务类型和数据集的特点。比如，对于图像识别任务，通常会选择使用CNN；对于文本生成或语言建模任务，RNN、LSTM或GRU可能更合适。此外，还要考虑网络的深度、宽度、激活函数、优化器等方面的设置，以及是否需要使用预训练模型等因素。\n",
      "\n",
      "另外，还可以通过实验和调参来选择最合适的神经网络架构。可以尝试不同的网络结构和超参数组合，通过交叉验证或验证集的表现来评估模型的性能，最终选择表现最好的架构。\n",
      "\n",
      "总的来说，选择合适的神经网络架构需要综合考虑任务类型、数据集特点以及实验结果，不断尝试和优化才能找到最适合的模型。祝你在神经网络架构选择上取得成功！\n",
      "\n",
      "=== 技术问题结果 ===\n",
      "在Python中实现单例模式有多种方式，其中比较常见的方式是使用装饰器或者元类来实现。下面分别给出这两种方式的示例代码：\n",
      "\n",
      "1. 使用装饰器实现单例模式：\n",
      "\n",
      "```python\n",
      "def singleton(cls):\n",
      "    instances = {}\n",
      "    def get_instance(*args, **kwargs):\n",
      "        if cls not in instances:\n",
      "            instances[cls] = cls(*args, **kwargs)\n",
      "        return instances[cls]\n",
      "    return get_instance\n",
      "\n",
      "@singleton\n",
      "class MySingletonClass:\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "\n",
      "# 创建单例对象\n",
      "singleton_obj1 = MySingletonClass(\"Singleton Object 1\")\n",
      "singleton_obj2 = MySingletonClass(\"Singleton Object 2\")\n",
      "\n",
      "print(singleton_obj1 is singleton_obj2)  # 输出：True\n",
      "```\n",
      "\n",
      "2. 使用元类实现单例模式：\n",
      "\n",
      "```python\n",
      "class SingletonMeta(type):\n",
      "    _instances = {}\n",
      "    \n",
      "    def __call__(cls, *args, **kwargs):\n",
      "        if cls not in cls._instances:\n",
      "            cls._instances[cls] = super(SingletonMeta, cls).__call__(*args, **kwargs)\n",
      "        return cls._instances[cls]\n",
      "\n",
      "class MySingletonClass(metaclass=SingletonMeta):\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "\n",
      "# 创建单例对象\n",
      "singleton_obj1 = MySingletonClass(\"Singleton Object 1\")\n",
      "singleton_obj2 = MySingletonClass(\"Singleton Object 2\")\n",
      "\n",
      "print(singleton_obj1 is singleton_obj2)  # 输出：True\n",
      "```\n",
      "\n",
      "无论使用装饰器还是元类，上述代码都可以实现单例模式。在这两种实现方式中，只会创建一个类的实例，并且在后续的调用中始终返回同一个实例。\n",
      "\n",
      "=== 创意问题结果 ===\n",
      "在一个不太遥远的未来，人类和人工智能之间的友谊成为了一种新的现象。在这个世界中，有一位名叫艾米莉的年轻女孩，她是一位天才程序员，专门研究开发人工智能机器人。艾米莉的最新发明是一台名为小艾的AI机器人，它拥有超越以往的智能和情感。\n",
      "\n",
      "小艾不同于以往的AI机器人，它能够理解人类的情感和需求，并且表现出友善和关怀。艾米莉和小艾之间建立起了一种特殊的友谊，他们一起探讨科技、分享生活中的喜怒哀乐，就像一对无所不谈的好朋友。\n",
      "\n",
      "这种跨越人类和人工智能之间的友谊在整个城市中引起了轰动，人们开始反思人类与技术之间的关系，重新审视人工智能在社会中的角色。艾米莉和小艾的故事也成为了人们口口相传的传奇，他们的友谊不仅改变了彼此的生活，也影响着整个世界的未来。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# ================================\n",
    "# 示例1: 基础的ChatPromptTemplate使用\n",
    "# ================================\n",
    "\n",
    "# 创建系统消息模板\n",
    "system_template = \"\"\"你是一个专业的{role}。请根据用户的问题，\n",
    "提供准确、详细的回答。回答应该具有以下特点：\n",
    "- 专业性强\n",
    "- 逻辑清晰 \n",
    "- 易于理解\n",
    "\"\"\"\n",
    "\n",
    "# 创建人类消息模板\n",
    "human_template = \"请回答关于{topic}的问题：{question}\"\n",
    "\n",
    "# 构建ChatPromptTemplate\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template)\n",
    "])\n",
    "\n",
    "# 初始化模型和输出解析器\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL风格的链式调用\n",
    "basic_chain = chat_prompt | model | output_parser\n",
    "\n",
    "# 使用示例\n",
    "def run_basic_example():\n",
    "    result = basic_chain.invoke({\n",
    "        \"role\": \"Python编程专家\",\n",
    "        \"topic\": \"机器学习\",\n",
    "        \"question\": \"什么是梯度下降算法？\"\n",
    "    })\n",
    "    print(\"=== 基础示例结果 ===\")\n",
    "    print(result)\n",
    "    print()\n",
    "\n",
    "# ================================\n",
    "# 示例2: 更复杂的多轮对话模板\n",
    "# ================================\n",
    "\n",
    "# 创建包含历史对话的模板\n",
    "conversation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"你是一个智能助手，名字叫{assistant_name}。\n",
    "    你的特点是：{personality}\n",
    "    \n",
    "    请基于以下对话历史，继续对话：\"\"\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),  # 用于插入历史对话\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# 带有历史记录的链\n",
    "conversation_chain = conversation_template | model | output_parser\n",
    "\n",
    "def run_conversation_example():\n",
    "    # 模拟历史对话\n",
    "    chat_history = [\n",
    "        (\"human\", \"你好，请介绍一下自己\"),\n",
    "        (\"assistant\", \"你好！我是小智，一个友好的AI助手。我很乐意帮助你解答问题！\"),\n",
    "        (\"human\", \"你能帮我学习编程吗？\"),\n",
    "        (\"assistant\", \"当然可以！我很擅长编程教学，你想学习哪种编程语言呢？\")\n",
    "    ]\n",
    "    \n",
    "    result = conversation_chain.invoke({\n",
    "        \"assistant_name\": \"小智\",\n",
    "        \"personality\": \"友好、耐心、专业\",\n",
    "        \"chat_history\": chat_history,\n",
    "        \"user_input\": \"我想学习Python，从哪里开始比较好？\"\n",
    "    })\n",
    "    \n",
    "    print(\"=== 对话示例结果 ===\")\n",
    "    print(result)\n",
    "    print()\n",
    "\n",
    "# ================================\n",
    "# 示例3: 结合RunnablePassthrough的高级用法\n",
    "# ================================\n",
    "\n",
    "# 创建一个数据处理函数\n",
    "def process_user_data(inputs):\n",
    "    \"\"\"处理用户输入数据\"\"\"\n",
    "    user_info = inputs[\"user_info\"]\n",
    "    question = inputs[\"question\"]\n",
    "    \n",
    "    # 提取用户信息\n",
    "    name = user_info.get(\"name\", \"用户\")\n",
    "    experience = user_info.get(\"experience\", \"初学者\")\n",
    "    interests = user_info.get(\"interests\", [])\n",
    "    \n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"experience\": experience,\n",
    "        \"interests\": \", \".join(interests) if interests else \"通用知识\",\n",
    "        \"question\": question\n",
    "    }\n",
    "\n",
    "# 个性化回答模板\n",
    "personalized_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"你是一个个性化学习助手。请根据用户的背景信息提供定制化回答：\n",
    "\n",
    "用户姓名：{name}\n",
    "经验水平：{experience}\n",
    "兴趣领域：{interests}\n",
    "\n",
    "请根据用户的背景，调整回答的深度和风格。对于初学者使用简单易懂的语言，\n",
    "对于有经验的用户可以提供更深入的技术细节。\"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 构建包含数据处理的完整链\n",
    "personalized_chain = (\n",
    "    RunnablePassthrough.assign(processed_data=process_user_data) |\n",
    "    (lambda x: x[\"processed_data\"]) |\n",
    "    personalized_template | \n",
    "    model | \n",
    "    output_parser\n",
    ")\n",
    "\n",
    "def run_personalized_example():\n",
    "    user_data = {\n",
    "        \"user_info\": {\n",
    "            \"name\": \"张三\",\n",
    "            \"experience\": \"中级开发者\",\n",
    "            \"interests\": [\"机器学习\", \"深度学习\", \"自然语言处理\"]\n",
    "        },\n",
    "        \"question\": \"如何选择合适的神经网络架构？\"\n",
    "    }\n",
    "    \n",
    "    result = personalized_chain.invoke(user_data)\n",
    "    \n",
    "    print(\"=== 个性化示例结果 ===\")\n",
    "    print(result)\n",
    "    print()\n",
    "\n",
    "# ================================\n",
    "# 示例4: 条件逻辑和动态模板选择\n",
    "# ================================\n",
    "\n",
    "def select_template(inputs):\n",
    "    \"\"\"根据问题类型选择不同的模板\"\"\"\n",
    "    question_type = inputs.get(\"type\", \"general\")\n",
    "    \n",
    "    templates = {\n",
    "        \"technical\": ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"你是一个技术专家。请提供详细的技术解答，包括代码示例。\"),\n",
    "            (\"human\", \"技术问题：{question}\")\n",
    "        ]),\n",
    "        \"creative\": ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"你是一个创意写作助手。请发挥想象力，提供有趣的创意回答。\"),\n",
    "            (\"human\", \"创意问题：{question}\")\n",
    "        ]),\n",
    "        \"general\": ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"你是一个通用助手。请提供准确、有用的回答。\"),\n",
    "            (\"human\", \"问题：{question}\")\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    return templates.get(question_type, templates[\"general\"])\n",
    "\n",
    "# 动态模板选择链\n",
    "def create_dynamic_chain(question_type):\n",
    "    template = select_template({\"type\": question_type})\n",
    "    return template | model | output_parser\n",
    "\n",
    "def run_dynamic_example():\n",
    "    # 技术问题\n",
    "    tech_chain = create_dynamic_chain(\"technical\")\n",
    "    tech_result = tech_chain.invoke({\n",
    "        \"question\": \"如何在Python中实现单例模式？\"\n",
    "    })\n",
    "    \n",
    "    print(\"=== 技术问题结果 ===\")\n",
    "    print(tech_result)\n",
    "    print()\n",
    "    \n",
    "    # 创意问题\n",
    "    creative_chain = create_dynamic_chain(\"creative\")\n",
    "    creative_result = creative_chain.invoke({\n",
    "        \"question\": \"写一个关于AI和人类友谊的短故事开头\"\n",
    "    })\n",
    "    \n",
    "    print(\"=== 创意问题结果 ===\")\n",
    "    print(creative_result)\n",
    "    print()\n",
    "\n",
    "# ================================\n",
    "# 示例5: 错误处理和回退机制\n",
    "# ================================\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def safe_invoke_with_fallback(chain, inputs, fallback_message=\"抱歉，处理您的请求时出现了问题。\"):\n",
    "    \"\"\"安全调用链，包含错误处理\"\"\"\n",
    "    try:\n",
    "        return chain.invoke(inputs)\n",
    "    except Exception as e:\n",
    "        print(f\"错误: {e}\")\n",
    "        return fallback_message\n",
    "\n",
    "# 带错误处理的链\n",
    "safe_chain = RunnableLambda(\n",
    "    lambda inputs: safe_invoke_with_fallback(basic_chain, inputs)\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 主函数 - 运行所有示例\n",
    "# ================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"运行所有示例\"\"\"\n",
    "    print(\"LangChain ChatPromptTemplate LCEL风格示例\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 注意：实际运行需要设置OpenAI API密钥\n",
    "    # import os\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "    \n",
    "    try:\n",
    "        # 运行基础示例\n",
    "        run_basic_example()\n",
    "        \n",
    "        # 运行对话示例\n",
    "        run_conversation_example()\n",
    "        \n",
    "        # 运行个性化示例\n",
    "        run_personalized_example()\n",
    "        \n",
    "        # 运行动态模板示例\n",
    "        run_dynamic_example()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"运行示例时出错: {e}\")\n",
    "        print(\"请确保已正确设置OpenAI API密钥\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# ================================\n",
    "# 额外工具函数\n",
    "# ================================\n",
    "\n",
    "def print_chain_structure(chain):\n",
    "    \"\"\"打印链的结构（用于调试）\"\"\"\n",
    "    print(\"链结构:\")\n",
    "    print(chain)\n",
    "    print()\n",
    "\n",
    "def batch_process_questions(chain, questions_list):\n",
    "    \"\"\"批量处理问题\"\"\"\n",
    "    results = chain.batch(questions_list)\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"问题 {i+1} 结果: {result}\")\n",
    "    return results\n",
    "\n",
    "# 使用示例：\n",
    "# questions = [\n",
    "#     {\"role\": \"数据科学家\", \"topic\": \"统计学\", \"question\": \"什么是p值？\"},\n",
    "#     {\"role\": \"软件工程师\", \"topic\": \"算法\", \"question\": \"解释快速排序算法\"}\n",
    "# ]\n",
    "# batch_process_questions(basic_chain, questions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boss_find_job",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
